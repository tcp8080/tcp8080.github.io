---
layout: post
categories: BilingualNews
---

Brieﬁng Social media and free speech
聊聊社交媒体和言论自由

The great clean-up
很棒的清理
```
Under public and official pressure, tech giants are removing more content.
在公众和官方的压力下，科技巨头正在删除更多内容。
But are they making the right calls? And should it be their decision?
但是他们打正确的电话吗？那应该是他们的决定吗？

Within hours of the publication of a New York Post article on October 14th, Twitter users began receiving strange messages. If they tried to share the story—a dubious “exposé” of emails supposedly from the laptop of Hunter Biden, son of the Democratic presidential nominee—they were told that their tweet could not be sent, as the link had been identiﬁed as harmful. Many Facebook users were not seeing the story at all: the social network had demoted it in the news feed of its 2.7bn users while its fact-checkers reviewed it.
在10月14日发表《纽约邮报》文章的几小时内，Twitter用户开始收到奇怪的消息。如果他们试图分享这个故事（据说是民主党总统候选人的儿子亨特·拜登（Hunter Biden）的笔记本电脑的电子邮件的可疑“暴露”），则他们被告知无法发送其推文，因为该链接被认为是有害的。许多Facebook用户根本看不到这个故事：该社交网络在其27亿用户的新闻提要中将其降级，而事实检查人员对其进行了审查。

If the companies had hoped that by burying or blocking the story they would stop people from reading it, the bet did not pay oﬀ. The article ended up being the most-discussed story of the week on both platforms—and the second-most talkedabout story was the fact that the social networks had tried to block it. The Post called it an act of modern totalitarianism, carried out “not [by] men in darkened cells driving screws under the ﬁngernails of dissidents, but Silicon Valley dweebs.” Republican senators vowed to extract testimony on anticonservative bias from Mark Zuckerberg and Jack Dorsey, the dweebs-in-chief of, respectively, Facebook and Twitter.
如果两家公司希望通过掩埋或阻止该故事来阻止人们阅读该故事，那么赌注就没有了。这篇文章最终成为这两个平台上本周讨论最多的故事，而谈论最多的故事是社交网络试图阻止它的事实。邮报称这是一种现代极权主义的行为，“不是在黑暗的牢房中的人在异议人士的指甲下打螺丝，而是在硅谷的矮人。”共和党参议员发誓要从马克·扎克伯格和杰克·多尔西（分别是Facebook和Twitter的总干事）的反保守主义偏见中提取证词。

The tale sums up the problem that social networks are encountering wherever they operate. They set out to be neutral platforms, letting users provide the content and keeping their hands oﬀ editorial decisions. Twitter executives used to joke that they were “the free-speech wing of the free-speech party”. Yet as they have become more active at algorithmically ranking the content that users upload, and moderating the undesirable stuﬀ, they have edged towards being something more like publishers. Mr Zuckerberg says he does not want to be an “arbiter of truth”. The Post episode fed the suspicion of many that, willingly or not, that is precisely what he is becoming.
这个故事总结了社交网络无论在哪里运行都遇到的问题。他们开始是中立的平台，让用户提供内容并保持编辑决策权。 Twitter高管曾经开玩笑说他们是“自由言论党的自由言论派”。然而，由于他们在算法上对用户上传的内容进行排名并减轻不良学习的行为变得更加活跃，因此他们已变得更像出版商。扎克伯格表示，他不想成为“真理的仲裁者”。邮政插曲引起了许多人的怀疑，无论他是否愿意，这正是他正在成为的人。

America’s fractious election campaign has only made more urgent the need to answer the unresolved questions about free expression online. What speech should be allowed? And who should decide? Rasmus Nielsen of the Reuters Institute at Oxford University describes this as a “constitutional moment” for how to regulate the private infrastructure that has come to support free expression around the world.
美国艰难的竞选活动仅使迫切需要回答有关在线自由表达的未解决问题。应该允许什么演讲？谁来决定？牛津大学路透学院的拉斯穆斯·尼尔森（Rasmus Nielsen）将这描述为如何规范私人基础设施的“宪法时刻”，而该基础设施已成为世界范围内支持言论自由的基础。

Social networks have been on the mother of all clean-ups. Facebook’s removal of hate speech has risen tenfold in two years (see chart 1 on next page). It disables some 17m fake accounts every single day, more than twice the number three years ago. YouTube, a video platform owned by Google with about 2bn monthly users, removed 11.4m videos in the past quarter, along with 2.1bn user comments, up from just 166m comments in the second quarter of 2018. Twitter, with a smaller base of about 350m users, removed 2.9m tweets in the second half of last year, more than double the amount a year earlier. TikTok, a Chinese short-video upstart, removed 105m clips in the ﬁrst half of this year, twice as many as in the previous six months (a jump partly explained by the ﬁrm’s growth).
社交网络是所有清理工作的源头。 Facebook在两年内消除仇恨言论的人数增加了十倍（请参阅下一页的图表1）。每天，大约有1700万个虚假帐户被禁用，是三年前的两倍多。 YouTube是Google拥有的视频平台，每月约有20亿用户，过去一个季度删除了1,140万个视频，以及21亿个用户评论，而2018年第二季度仅为1.66亿个评论。Twitter，基数较小去年下半年，有3.5亿用户删除了290万条推文，是去年同期的两倍多。中国的短视频新贵TikTok在今年上半年删除了1.05亿个剪辑，是前六个月的两倍（这一增长的部分原因是该公司的增长）。


Artiﬁcial intelligence has helped to make such a clean-up possible. Most offending content is taken down before any user has had a chance to ﬂag it. Some lends itself readily to policing with machines: more than 99% of the child-nudity posts Facebook takes down are removed before anyone has reported them, but most of the bullying or harassment is ﬂagged by users rather than robots. Two years ago Facebook’s ai removed a post referring to “merciless Indian Savages”, before human moderators realised it was a quote from the Declaration of Independence. Facebook now employs about 35,000 people to moderate content. In May the company agreed to pay $52m to 11,250 moderators who developed post-traumatic stress disorder from looking at the worst of the internet.
人工智能有助于进行此类清理。在任何用户有机会对其进行标记之前，大多数令人反感的内容都将被删除。有些人很容易与机器保持警惕：在任何人举报之前，Facebook删除的99％以上的儿童裸露帖子都已被删除，但是大多数欺凌或骚扰行为是由用户而不是机器人来标记的。两年前，在人类主持人意识到这是《独立宣言》的引文之前，Facebook的AI删除了一篇提及“无情的印第安人野蛮人”的文章。 Facebook现在雇用约35,000名员工来审核内容。今年5月，该公司同意向11,250名主持人支付5,200万美元，这些主持人从看互联网的最糟糕状况发展为创伤后压力障碍。


Discussions about free speech that may once have seemed abstract have become all too practical—the murder of Samuel Paty near Paris last week being the latest shocking reminder. Social networks tightened their policies on terrorism after Islamist attacks in Europe in 2015 and an anti-Muslim rampage in New Zealand last year, which was live-streamed on Facebook and shared on YouTube. The American election and Brexit referendum of 2016 forced them to think again about political communication. Twitter banned all political ads last year, and Facebook and Google have said they will ban them around the time of this year’s election on November 3rd.
关于言论自由的讨论似乎曾经是抽象的，已经变得太实际了-上周在巴黎附近谋杀塞缪尔·帕蒂是最新的令人震惊的提醒。在2015年欧洲伊斯兰袭击和去年新西兰发生反穆斯林猖ramp事件之后，社交网络收紧了对恐怖主义的政策，这些信息在Facebook上进行直播并在YouTube上共享。 2016年美国大选和英国脱欧公投迫使他们重新考虑政治沟通。 Twitter去年禁止了所有政治广告，Facebook和Google表示将在今年11月3日选举之际禁止它们。

The companies have also improved their scrutiny of far-ﬂung countries, after criticism of their earlier negligence in places such as Myanmar, where Facebook played a “determining role” in the violence against Rohingya Muslims, according to the un (see Asia section). This week Facebook announced that it had hired more content-reviewers ﬂuent in Swahili, Amharic, Zulu, Somali, Oromo and Hausa, ahead of African elections. Its ai is learning new languages, and hoovering up rulebreaking content as it does so.
联合国称，在批评缅甸早先在缅甸等地的疏忽之后，这两家公司还改善了对遥远国家的审查。 Facebook本周宣布，在非洲大选之前，它已在斯瓦希里语，阿姆哈拉语，祖鲁语，索马里语，奥罗莫语和豪萨语聘请了更多内容审查员。它的目的是学习新语言，并在此过程中徘徊违反规则的内容。
```

The room where it happens
发生的房间
```
Some tech bosses have been rethinking their approach to the trade-oﬀs between free expression and safety. Last October, in a speech at Georgetown University, Mr Zuckerberg made a full-throated defence of free speech, warning: “More people across the spectrum believe that achieving the political outcomes they think matter is more important than every person having a voice. I think that’s dangerous.” Yet this year, as misinformation about covid-19 ﬂourished, Facebook took a harder line on fake news about health, including banning anti-vaccination ads. And this month it banned both Holocaust denial and groups promoting QAnon, a crackpot conspiracy.
一些技术老板一直在重新思考他们在表达自由与安全之间进行权衡的方法。去年10月，扎克伯格在乔治敦大学的演讲中全力捍卫言论自由，并警告说：“越来越多的人相信，实现他们认为重要的政治成果比每个有发言权的人都重要。我认为这很危险。”然而，今年以来，随着有关covid-19的错误信息泛滥，Facebook对有关健康的虚假新闻采取了更严厉的态度，包括禁止接种疫苗。本月，它禁止否认大屠杀，并禁止团体宣传QAnon（一种阴谋诡计）。

The pressure from the media is to “remove more, remove more, remove more”, says one senior tech executive. But in some quarters unease is growing that the ﬁrms are removing too much. In America this criticism comes mostly from the right, which sees Silicon Valley as a nest of liberals. It is one thing to zap content from racists and Russian trolls; it is another to block the New York Post, one of America’s highest-circulation newspapers, founded by Alexander Hamilton (who admittedly might not have approved of its current incarnation, under Rupert Murdoch).
一位高级技术主管说，媒体的压力是“删除更多，删除更多，删除更多”。但是在某些情况下，人们越来越不安的是，这些公司去除了太多东西。在美国，这种批评主要来自右翼，它把硅谷视为自由主义者的巢穴。剥夺种族主义者和俄罗斯巨魔的满足感是一回事。这是另一个封锁《纽约邮报》的消息，这是美国发行量最高的报纸之一，由亚历山大·汉密尔顿（亚历山大·汉密尔顿（亚历山大·汉密尔顿）承认，在鲁珀特·默多克（Rupert Murdoch）的领导下，他可能尚未批准其当前的版本）。

Elsewhere, liberals worry that whistleblowing content is being wrongly taken down. YouTube removed footage from users in Syria that it deemed to break its guidelines on violence, but which was also potential evidence of war crimes. Until last year TikTok’s guidelines banned criticism of systems of government and “distortion” of historical events including the massacre near Tiananmen Square.
在其他地方，自由主义者担心举报内容被错误地删除。 YouTube从叙利亚的用户中删除了一些影片，认为该影片违反了暴力准则，但也可能是战争罪的证据。直到去年，TikTok的指导方针都禁止批评政府体制和“扭曲”历史事件，包括天安门广场附近的大屠杀。

Where both camps agree is in their unease that it is falling to social networks to decide what speech is acceptable. As private companies they can set their own rules about what to publish (within the conﬁnes of the laws of countries where they operate). But they have come to play a big role in public life. Mr Zuckerberg himself compares Facebook to a “town square”.
两个阵营都同意的地方是，他们不安地决定由哪种社交网络来决定哪种言语是可以接受的。作为私人公司，他们可以针对出版内容制定自己的规则（在其经营所在国家/地区的法律范围内）。但是它们已经在公共生活中发挥了重要作用。扎克伯格本人将Facebook比作“城市广场”。

Rival social networks promising truly free speech have struggled to overcome the network eﬀects enjoyed by the incumbents. One, Gab, attracted neo-Nazis. Another, Parler, has been promoted by some Republican politicians but so far failed to take oﬀ. (It is also grappling with freespeech dilemmas of its own, reluctantly laying down rules including no sending of photos of fecal matter.) Outside China, where Facebook does not operate, four out of ten people worldwide use the platform; WhatsApp and Instagram, which it also owns, have another 3bn or so accounts between them. “Frankly, I don’t think we should be making so many important decisions about speech on our own either,” Mr Zuckerberg said in his Georgetown speech.
那些希望提供真正的言论自由的竞争性社交网络一直在努力克服在位者享有的网络影响。其中一位是加布（Gab），吸引了新纳粹分子。另一名共和党政客提拔了帕勒（Parler），但至今未能如愿。 （它也正努力解决自己的言论自由困境，不情愿制定规则，包括不发送粪便照片。）在中国之外，Facebook不运营，全球十分之四的人使用该平台；它同时拥有的WhatsApp和Instagram之间还有另外30亿个左右的帐户。扎克伯格在乔治敦（Georgetown）演讲中说：“坦率地说，我也不应该就我们自己的演讲做出这么多重要的决定。”
```

Say no to this
对这个说不
```
Bill Clinton once said that attempting to regulate the internet, with its millions of diﬀerent sites, would be “like trying to nail Jell-O to the wall”. But the concentration of the social-media market around a few companies has made the job easier.
比尔·克林顿曾经说过，试图对拥有数百万个不同站点的互联网进行监管，就像“试图将Jell-O钉在墙上”。但是社交媒体市场集中在一些公司周围使工作变得容易了。

Twitter has faced steep growth in the number of legal requests for content removal, from individuals as well as governments (see chart 2). Last year Google received 30,000 requests from governments to remove pieces of content, up from a couple of thousand requests ten years ago (see chart 3 on next page). And Facebook took down 33,600 pieces of content in response to legal requests. They included a Photoshopped picture of President Emmanuel Macron in pink underwear, which French police wanted removed because it broke a law from 1881 restricting press freedom.
Twitter面临着来自个人和政府的删除内容的法律请求数量的急剧增长（见图2）。去年，谷歌收到各国政府的30,000项删除内容的请求，而十年前的请求是2,000项（参见下页表3）。根据法律要求，Facebook删除了33,600条内容。其中包括一张穿着粉红色内裤的伊曼纽尔·马克龙（Emmanuel Macron）总统的Photoshopped照片，法国警察希望将其删除，因为这违反了1881年的一项限制新闻自由的法律。

In America the government is prevented from meddling too much with online speech by the First Amendment. Section 230 of the Communications Decency Act gives online platforms further protection, exempting them from liability for the content they publish. But carve-outs to this exemption are growing. Firms cannot avoid responsibility for copyright infringements, posts that break federal criminal law, or which enable sex traﬃcking. The latter exemption, made in 2018, had an impact on speech that was greater than its drafting implied: sites including Tumblr and Craigslist concluded that, rather than risk prosecution, they would stop publishing adult material of all sorts.
在美国，《第一修正案》禁止政府过多干预在线演讲。 《通讯端正法》第230条为在线平台提供了进一步的保护，使它们免于对其发布的内容承担责任。但是，对这种豁免的限制正在增加。公司无法避免对侵犯版权，违反联邦刑法或进行性交易的责任。后者于2018年获得豁免，对言论的影响大于其起草的含义：包括Tumblr和Craigslist在内的网站得出的结论是，他们将停止发布各种成人材料，而不是进行起诉。

In Europe regulation has gone further. In 2014 the European Court of Justice (ECJ) established the “right to be forgotten” when it found in favour of a Spanish man who wanted Google to remove old references to his history of indebtedness. Since then Google has ﬁelded requests for about half a million urls to be removed each year, and granted about half of them. Last year the ecj ruled that European countries could order Facebook to remove content worldwide, not just for users within their borders. The European Audiovisual Media Services Directive requires online video services to take “appropriate measures” to protect viewers from harmful or illegal content, including setting up age checks. The European Commission is to publish a Digital Services Act, expected to impose further obligations on internet companies.
在欧洲，法规进一步发展。 2014年，欧洲法院（ECJ）裁定赞成一名希望谷歌删除其债务历史的旧提要的西班牙人，从而确立了“被遗忘的权利”。自那时以来，Google提出了每年删除大约一百万个网址的请求，并批准了其中的一半。去年，欧洲法院裁决欧洲国家可以命令Facebook在全球范围内删除内容，而不仅仅是针对其境内的用户。欧洲视听媒体服务指令要求在线视频服务采取“适当措施”，以保护观众免受有害或非法内容的侵害，包括设置年龄检查。欧盟委员会将发布《数字服务法》，预期将对互联网公司施加进一步的义务。

National governments have also set their own rules, notably Germany, whose Network Enforcement Act of 2017 threatens platforms with ﬁnes of up to €50m ($60m) if they fail to take down illegal content within 24 hours of notiﬁcation. In response Facebook opened a new moderation centre in Germany. The trouble with privatising the enforcement of the law in this way, points out Mr Nielsen, is that the companies have big incentives to err on the side of caution. A judge may use discretion to ignore rules on speech that are seldom applied (such as a German law that until recently banned insulting a foreign head of state). But a social-media company has no reason to risk ignoring a law.
各国政府还制定了自己的规则，尤其是德国。德国在2017年的《网络执行法》中威胁，如果未能在通知后24小时内删除违法内容，则平台将面临高达5000万欧元（合6000万美元）的罚款。作为回应，Facebook在德国开设了一个新的审核中心。尼尔森先生指出，以这种方式将执法私有化的麻烦在于，两家公司有很大的动机去谨慎行事。法官可以运用酌处权来忽略很少使用的言语规则（例如直到最近才禁止侮辱外国国家元首的德国法律）。但是，社交媒体公司没有理由冒险忽视法律。
```

Who tells your story
谁在讲你的故事
```
Some governments are leaning on social networks to remove content that may be legal. The social-media platforms have their own rules that go further than most governments’. A ban on material that could interfere with “civic integrity” may sound like something from communist China; it is actually in Twitter’s rules. London’s Metropolitan Police has a unit that scours platforms for terrorism-related content, which it “requests” be taken down for breaching the platform’s terms of service—even though the material may not break any law.
一些政府正依靠社交网络删除可能合法的内容。社交媒体平台有自己的规则，比大多数政府的规则要严格得多。禁止可能干扰“公民诚信”的材料听起来像共产主义中国。这实际上是Twitter的规则。伦敦大都会警察局设有一个部门，负责搜查与恐怖主义有关的内容的平台，尽管该材料可能未违反任何法律，但由于违反平台的服务条款而被“撤消”。

“Authoritarian governments are taking cues from the loose regulatory talk among democracies,” writes David Kaye, a former un special rapporteur on free expression. Last year Singapore passed what it described as an anti-fake-news law, banning the online publication of lies that could harm the public interest. Thailand has enforced its lèse-majesté laws online, in August ordering Facebook to block a critical group called Royalist Marketplace, which with more than 1m members was one of the largest on the platform. (Facebook complied, but is suing the Thai government for breaking human-rights law.)
“专制政府从民主国家之间松散的监管言论中汲取了线索，”前非言论自由特别报告员戴维·凯伊（David Kaye）写道。去年，新加坡通过了所谓的反假新闻法，禁止在线发布可能损害公共利益的谎言。泰国已经在网上执行了淫荡法律，今年8月命令Facebook封锁一个名为Royalist Marketplace的重要组织，该组织拥有超过100万名成员，是该平台上最大的组织之一。 （Facebook遵守，但正在起诉泰国政府违反人权法。）

If neither governments nor executives make reliable custodians of free speech, what can be done to keep the internet a tolerable place while protecting freedom of expression? An increasingly common answer in Silicon Valley is to draw a distinction between freedom of speech and “freedom of reach”: leave posts up, but make them less visible and viral.
如果政府和行政人员都不是言论自由的可靠保管人，那么在保护言论自由的同时，如何使互联网成为一个可以容忍的地方呢？在硅谷，一个越来越普遍的答案是在言论自由和“伸手可及的自由”之间进行区分：将帖子保留起来，但使其不那么可见和病毒式传播。

Last year YouTube changed its algorithm so that videos that were borderline cases for deletion were recommended less often. After the bombings of churches and hotels in Sri Lanka at Easter in 2019, Facebook prevented the resharing of posts by friends of friends, to stop inﬂammatory content travelling too far or fast; this rule is in place in Ethiopia and Myanmar. Twitter has tried to stop people from mindlessly sharing fake news by prompting them to read articles before they retweet them. Platforms are adding more labels to content, warning users that it is misleading.
去年，YouTube更改了算法，因此，很少建议删除属于临界案例的视频。在2019年复活节在斯里兰卡的教堂和旅馆遭到炸弹袭击之后，Facebook阻止了朋友之友转贴帖子，以阻止即时发布的内容过快或过快;埃塞俄比亚和缅甸都有这项规定。 Twitter试图通过促使人们在转发其内容之前阅读文章，来阻止人们盲目共享虚假新闻。平台正在为内容添加更多标签，警告用户该内容具有误导性。

Another idea gaining momentum is that ﬁrms should make their data available for audit just as listed companies must open up their accounts. Their internal processes could also be more transparent. At Facebook there is an odd tension between its earnest approach to policymaking, with fortnightly “mini-legislative sessions”, and the fact that every month Mr Zuckerberg personally takes a handful of the hardest decisions on content moderation. Treating the big calls as “corner-office decisions” is a mistake, believes Mr Kaye: better for companies to say, “We have these rules, we’re going to apply them neutrally. And we don’t want that process to be corrupted by political pressure.”
另一个获得动力的想法是，公司应该像上市公司必须开设其帐户一样，将其数据提供给审计。他们的内部流程也可能更加透明。在Facebook，其认真的决策方法（每两周举行一次“微型立法会议”）与扎克伯格每个月亲自就内容审核做出最艰难的决定之间存在一种奇怪的张力。凯伊认为，将大电话视为“角落办公室的决定”是一个错误：对于公司而言，最好说：“我们有这些规则，我们将中立地应用它们。而且我们不希望该过程被政治压力破坏。”

Facebook took a step towards such a system on October 22nd with the launch of its Oversight Board, a watchdog made up of 20 members of the great and good who will scrutinise its moderation decisions and issue binding rulings. The board’s scope is narrower than some had hoped. It can consider only whether deleted posts should be reinstated. It merely applies Facebook’s rules, rather than setting them. It cannot consider posts that have been algorithmically demoted, as opposed to deleted. So some of the most prominent recent controversies—Facebook’s decision to leave up a contentious post by Donald Trump, its removal of QAnon, its reversal on Holocaust denial and its demotion of the Post story—are outside the board’s jurisdiction.
10月22日，Facebook推出了监督委员会，朝着这样的系统迈出了一步。监督委员会由20位优秀人士组成，负责监督其温和的决定并发布具有约束力的裁决。董事会的范围比某些人希望的要窄。它只能考虑是否应恢复已删除的帖子。它仅适用Facebook的规则，而不是设置它们。它不能考虑通过算法降级的帖子，而不是删除的帖子。因此，最近一些最著名的争议（董事会决定放弃唐纳德·特朗普的一个有争议的职位，撤回QAnon，撤销对大屠杀的否认和贬低该职位的报道）不在董事会的管辖范围之内。
```

History has its eyes on you
历史注视着你
```
Yet as Alan Rusbridger, a former Guardian editor and member of the new board, puts it, it is a “revolutionary thought”. “A company that has notoriously been very reluctant to surrender control on anything has handed over…the power to make some pretty consequential decisions on its behalf,” he says. He hopes the board will get more powers over time. Facebook says this is premature. But Sir Nick Clegg, its head of global aﬀairs, hopes the board’s remit might one day expand to consider cases submitted by other social networks.
然而，正如前《卫报》编辑兼新董事会成员艾伦·罗斯布里奇（Alan Rusbridger）所说，这是一种“革命思想​​”。他说：“众所周知，一家非常不愿放弃对任何事情的控制权的公司已经移交了……代表其做出一些相当重要的决定的权力。”他希望董事会将随着时间的推移获得更多权力。 Facebook说这还为时过早。但是其全球航空事务负责人尼克·克莱格爵士（Sir Nick Clegg）希望董事会的职权范围有一天可以扩大到考虑其他社交网络提交的案件。

Others have similar ideas. Article 19, a free-speech lobby group, has suggested that platforms could outsource their moderation decisions to non-governmental “social-media councils”, something like the press watchdogs that in many countries hold newspapers to a voluntary code.
其他人有类似的想法。自由言论游说组织第19条建议，平台可以将其主持人的决定外包给非政府的“社会媒体委员会”，就像许多国家的新闻监视机构一样，使报纸遵守自愿守则。

For now, the social networks have to get through perhaps the hardest fortnight in their short history. They face the possibility of having to deploy content-moderation tools developed for fragile, emerging democracies in their home country. Facebook removed 120,000 pieces of content aimed at voter suppression in America in the past quarter. The New York Post aﬀair does not bode well for how the companies might handle the fallout from a contested election. “When they appeared to depart from their policies they opened themselves up to the very charges of bias that followed,” says Evelyn Douek of Harvard Law School. As the election approaches, they need to “tie themselves to a mast” of clear rules, she says. A storm is coming.
就目前而言，社交网络必须度过其短暂历史上最艰难的两周。他们面临着必须部署针对其本国脆弱的新兴民主国家开发的内容审核工具的可能性。 Facebook在过去一个季度中删除了12万条旨在压制美国选民的内容。 《纽约邮报》的报道对于两家公司如何应对有争议的选举产生的后果并不是一个好兆头。哈佛法学院的伊夫琳·杜埃克（Evelyn Douek）说：“当他们似乎背离政策时，他们便公开接受随之而来的偏见。”她说，随着选举的临近，他们需要“束手无策”。风暴来了。
```
translated from The Economist 20201024 P20-P22
